# Running Spark

빅데이타 분석을 위한 스파크 사용법을 설명합니다.

## flintrock 설치

[flintrock](./flintrock.md) 을 이용해 스파크 클러스터를 생성합니다.

## pyspark 설치

스파크 클러스터에 [pyspark](./pyspark.md) 를 설치합니다.

## aws s3 접근하기

[AWS S3](./s3.md) 에 데이타 파일을 올려서 데스트 데이타로 사용합니다.

## Spark SQL 사용하기

[Spark SQL](./spark-sql.md) 를 이용해 데이타를 분석할 수 있습니다.

## Jupyter 로 스파크 실행하기

[Jupyter](./jupyter.md) 를 이용해 스파크를 실행할 수 있습니다.

## Hadoop 설정하기

[Hadoop](./hadoop.md) 을 이용하여 노드간 파일을 공유할 수 있습니다.

## yarn 설정하기

[yarn](./yarn.md) 을 이용해 클러스터를 컨트롤 할 수 있습니다.

## Spark 튜닝하기

[Spark 튜닝](./tuning.md) 을 위한 파라미터를 확인해 봅니다.

## 한방 정리

위 내용을 [한번에 정리](./summary.md) 해 봅니다.
